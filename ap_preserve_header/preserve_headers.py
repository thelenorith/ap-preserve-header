"""
Generated By: Cursor (Claude Sonnet 4.5)

This script preserves FITS headers from file path key-value pairs into .fits and .xisf files.
It extracts key-value pairs encoded in directory paths and filenames and inserts them
as FITS header keywords, but only if the header value doesn't already match the path value.
"""

import argparse
import logging
import re
from pathlib import Path
from typing import Any, Dict, List

from astropy.io import fits
from ap_common.fits import get_file_headers, update_xisf_headers
from ap_common.logging_config import setup_logging
from ap_common.progress import progress_iter
from xisf import XISF

from . import config

# Module-level logger, configured in main()
logger = logging.getLogger(__name__)


def extract_key_value_pairs(path: Path) -> Dict[str, str]:
    """
    Extract key-value pairs from a file path using ap-common's parsing logic.

    Key-value pairs are encoded in directory names and filenames using patterns like:
    - KEY_value (underscore separator)
    - KEY-value (hyphen separator)

    Multiple key-value pairs can exist in a single directory name, e.g.:
    - DATE_2026-01-20_INSTRUME_ATR585M_OFFSET_150

    Uses ap-common's get_file_headers for parsing, then applies FITS-specific
    uppercase normalization to keys.

    Args:
        path: Full path to the file

    Returns:
        Dictionary mapping header keys (uppercase) to values extracted from the path
    """
    # Use ap-common's path parsing logic (without normalization or special profile/object handling)
    parsed = get_file_headers(
        filename=str(path),
        profileFromPath=False,
        objectFromPath=False,
        normalize=False,
    )

    # Remove the "filename" key that get_file_headers adds
    parsed.pop("filename", None)

    # Apply FITS-specific uppercase normalization to keys
    key_value_pairs: Dict[str, str] = {}
    for key, value in parsed.items():
        # Convert key to uppercase for FITS convention
        key_upper = key.upper()
        # Convert value to string and strip whitespace to avoid trailing spaces
        value_str = str(value).strip() if value is not None else ""
        key_value_pairs[key_upper] = value_str

    return key_value_pairs


def read_fits_header(filepath: Path) -> fits.Header:
    """
    Read FITS header from a .fits file.

    Args:
        filepath: Path to the FITS file

    Returns:
        FITS header object (copy that remains valid after file is closed)

    Raises:
        Exception: If file cannot be read or opened (logged as warning before raising)
    """
    try:
        # Open in read-only mode since we're just reading, not updating
        with fits.open(str(filepath), mode="readonly") as hdul:
            # Return a copy of the header so it remains valid after context manager exits
            return hdul[0].header.copy()
    except Exception as e:
        # Log error internally for consistency with read_xisf_header
        logger.warning(f"Error reading FITS header from {filepath}: {e}")
        raise


def read_xisf_header(filepath: Path) -> Dict[str, Any]:
    """
    Read header from a .xisf file.

    Args:
        filepath: Path to the XISF file

    Returns:
        Dictionary of header keywords and values (empty dict if file has no header)

    Raises:
        Exception: If file cannot be read or opened (logged as warning before raising)
    """
    try:
        # Use XISF.read() to get image data and metadata
        image_metadata: dict[str, Any] = {}
        xisf_metadata: dict[str, Any] = {}
        XISF.read(
            str(filepath), image_metadata=image_metadata, xisf_metadata=xisf_metadata
        )

        # Extract FITSKeywords from image metadata
        header_dict = {}
        if "FITSKeywords" in image_metadata:
            fits_keywords = image_metadata["FITSKeywords"]
            if isinstance(fits_keywords, dict):
                for key, value_list in fits_keywords.items():
                    if isinstance(value_list, list) and len(value_list) > 0:
                        # FITSKeywords values are lists of dicts with 'value' and 'comment'
                        header_dict[key.upper()] = str(value_list[0].get("value", ""))
                    else:
                        header_dict[key.upper()] = str(value_list) if value_list else ""
        return header_dict
    except Exception as e:
        # Log error internally for consistency with read_fits_header
        logger.warning(f"Error reading XISF header from {filepath}: {e}")
        raise


def get_header_value(header: fits.Header | Dict[str, Any], key: str) -> str | None:
    """
    Get a header value from either a FITS header or XISF header dict.

    Args:
        header: FITS header object or XISF header dictionary
        key: Header keyword (will be uppercased)

    Returns:
        Header value as string, or None if not found
    """
    key_upper = key.upper()
    if isinstance(header, fits.Header):
        try:
            value = header[key_upper]
            # Convert to string for comparison
            if isinstance(value, (int, float)):
                return str(value)
            return str(value).strip()
        except KeyError:
            return None
    else:  # Dict (XISF)
        if key_upper in header:
            value = header[key_upper]
            if isinstance(value, (int, float)):
                return str(value)
            return str(value).strip()
    return None


def set_header_value(
    header: fits.Header | Dict[str, Any], key: str, value: str, comment: str = ""
) -> None:
    """
    Set a header value in either a FITS header or XISF header dict.

    Args:
        header: FITS header object or XISF header dictionary
        key: Header keyword (will be uppercased)
        value: Value to set
        comment: Optional comment for the header
    """
    key_upper = key.upper()
    if isinstance(header, fits.Header):
        header[key_upper] = (value, comment)
    else:  # Dict (XISF)
        header[key_upper] = value


def update_fits_header(filepath: Path, updates: Dict[str, str]) -> bool:
    """
    Update FITS header with new keywords.

    Args:
        filepath: Path to the FITS file
        updates: Dictionary of header keywords and values to update

    Returns:
        True if file was modified, False otherwise
    """
    modified = False
    with fits.open(str(filepath), mode="update") as hdul:
        header = hdul[0].header
        for key, value in updates.items():
            if key not in header or str(header[key]).strip() != value:
                header[key] = (value, "From file path")
                modified = True
                logger.debug(f"  Updated {key} = {value}")
        if modified:
            hdul.flush()
    return modified


def should_include_header(key: str, include_headers: List[str]) -> bool:
    """
    Determine if a header key should be included.

    Args:
        key: Header keyword
        include_headers: List of specific headers to include (required)

    Returns:
        True if header should be included, False otherwise
    """
    key_upper = key.upper()
    # Only include headers in the include list
    return key_upper in [h.upper() for h in include_headers]


def preserve_headers(
    root_dir: str,
    include_headers: List[str],
    dryrun: bool = False,
    quiet: bool = False,
) -> None:
    """
    Preserve FITS headers from file path key-value pairs into .fits and .xisf files.

    Args:
        root_dir: Root directory to scan for FITS and XISF files
        include_headers: List of specific header keys to include (required, explicit inclusion only)
        dryrun: Perform dry run without actually modifying files
        quiet: Suppress progress indicators
    """
    root_path = Path(root_dir).resolve()

    if not root_path.exists():
        raise ValueError(f"Root directory does not exist: {root_dir}")

    if not root_path.is_dir():
        raise ValueError(f"Path is not a directory: {root_dir}")

    # Find all FITS and XISF files using patterns from config
    fits_pattern = re.compile(config.INPUT_PATTERN_FITS)
    xisf_pattern = re.compile(config.INPUT_PATTERN_XISF)

    fits_files = []
    xisf_files = []
    for filepath in root_path.rglob("*"):
        if filepath.is_file():
            filename = str(filepath)
            if fits_pattern.match(filename):
                fits_files.append(filepath)
            elif xisf_pattern.match(filename):
                xisf_files.append(filepath)

    all_files = fits_files + xisf_files

    logger.info(f"Found {len(fits_files)} FITS files and {len(xisf_files)} XISF files")

    # Track statistics
    files_processed = 0
    files_updated = 0
    files_no_updates = 0
    files_failed = 0

    for filepath in progress_iter(
        all_files, desc="Processing files", unit="files", enabled=not quiet
    ):
        files_processed += 1
        logger.debug(f"\nProcessing: {filepath}")

        # Extract key-value pairs from file path
        path_key_values = extract_key_value_pairs(filepath)

        if not path_key_values:
            logger.debug("  No key-value pairs found in path")
            files_no_updates += 1
            continue

        # Filter to only include specified headers
        updates = {}
        for key, value in path_key_values.items():
            if should_include_header(key, include_headers):
                updates[key] = value

        if not updates:
            logger.debug("  No headers to include after filtering")
            files_no_updates += 1
            continue

        # Check current header values - only update if different
        final_updates = {}
        is_fits = fits_pattern.match(str(filepath)) is not None

        try:
            if is_fits:
                header = read_fits_header(filepath)
            else:
                header = read_xisf_header(filepath)

            for key, path_value in updates.items():
                current_value = get_header_value(header, key)
                if current_value != path_value:
                    final_updates[key] = path_value
                    logger.debug(
                        f"  Will update {key}: '{current_value}' -> '{path_value}'"
                    )
                else:
                    logger.debug(f"  Skipping {key}: already set to '{path_value}'")

        except Exception:
            # Error already logged by read_fits_header or read_xisf_header, just track failure
            files_failed += 1
            continue

        if not final_updates:
            logger.debug("  No updates needed")
            files_no_updates += 1
            continue

        # Apply updates
        if dryrun:
            logger.debug(f"  [DRYRUN] Would update {len(final_updates)} header(s)")
            files_updated += 1
        else:
            try:
                if is_fits:
                    modified = update_fits_header(filepath, final_updates)
                else:
                    modified = update_xisf_headers(
                        str(filepath), final_updates, comments=None, check_existing=True
                    )

                if modified:
                    files_updated += 1
                    logger.debug("  File modified successfully")
                else:
                    files_no_updates += 1
            except Exception as e:
                logger.warning(f"  Error updating file {filepath}: {e}")
                files_failed += 1
                continue

    # Print summary
    logger.info(
        f"Summary: {files_processed} processed, "
        f"{files_updated} updated, "
        f"{files_no_updates} no updates needed, "
        f"{files_failed} failed"
    )


def main() -> None:
    """Main entry point for the command-line interface."""
    parser = argparse.ArgumentParser(
        description="Preserve FITS headers from file path key-value pairs into .fits and .xisf files"
    )
    parser.add_argument(
        "root_dir",
        type=str,
        help="Root directory to scan for FITS and XISF files",
    )
    parser.add_argument(
        "--include",
        type=str,
        nargs="+",
        required=True,
        help="Specific header keys to include (required, explicit inclusion only)",
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug output (sets logging level to DEBUG)",
    )
    parser.add_argument(
        "--dryrun",
        action="store_true",
        help="Perform dry run without actually modifying files",
    )
    parser.add_argument(
        "--quiet",
        "-q",
        action="store_true",
        help="Suppress progress output",
    )

    args = parser.parse_args()

    # Configure logging using ap-common's setup_logging
    setup_logging(name=__name__, debug=args.debug, quiet=args.quiet)

    preserve_headers(
        root_dir=args.root_dir,
        include_headers=args.include,
        dryrun=args.dryrun,
        quiet=args.quiet,
    )


if __name__ == "__main__":
    main()
